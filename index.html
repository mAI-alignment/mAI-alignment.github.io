<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>mAI alignment lab</title>
    <meta name="author" content="Florian  Mai">
    <meta name="description" content="Junior Research Group at University of Bonn focusing on AI alignment and safety issues.
">
    <meta name="keywords" content="ai alignment, ai safety, machine learning, research, university of bonn">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/logo-favicon.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://al-folio.github.io/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <!-- Logo -->
          <a class="navbar-brand" href="/" style="margin-right: 1rem;">
            <img src="/assets/img/logo.png" alt="mAI alignment lab" style="height: 70px; width: auto;">
          </a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/team/">team</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">safety reading group</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <h1 class="post-title" style="font-weight: bold; color: #0c446b;">
           mAI alignment lab
          </h1>
          <p class="desc" style="font-weight: bold; color: #0c446b;">Junior Research Group at University of Bonn focusing on AI alignment and safety issues</p>
        </header>

        <article>
          <div class="profile float-right">
          </div>

          <div class="clearfix">
            <h2 id="about">About</h2>

<p>Welcome to the mAI alignment lab, a Junior Research Group at the University of Bonn led by Dr. Florian Mai.</p>

<p>Our research focuses on AI alignment and safety issues, exploring how to ensure that current and future advanced AI systems are acting reliably in accordance with human values.</p>

<h2 id="research-interests">Research Interests</h2>

<ul>
  <li>Scalable Oversight</li>
  <li>Value alignment</li>
  <li>Emergent misalignment</li>
  <li>Planning</li>
  <li>LLM training</li>
</ul>

<h2 id="current-projects">Current Projects</h2>

<ul>
  <li>
    <p><strong><a href="/projects/superalignment-task-decomposition/">Scalable Oversight by Learning to Decompose Tasks</a></strong>: Exploring how AI systems can learn to break complex tasks into manageable subtasks for reliable human oversight, advancing the frontier of superalignment research.</p>
  </li>
  <li>
    <p><strong><a href="/projects/learning-to-plan/">Learning to Plan from Unlabeled Data</a></strong>: Developing planning capabilities for language models through self-supervised learning.</p>
  </li>
</ul>

<h2 id="join-us">Join Us</h2>

<p>We currently have no open positions available. However, if you are interested in collaborating with our research group, please feel free to send an email to Dr. Florian Mai at fmai@uni-bonn.de.</p>

          </div>

          <!-- News -->
          <h2><a href="/news/" style="color: #0c446b;">news</a></h2>
          <div class="news">
            <div class="table-responsive">
              <table class="table table-sm table-borderless">
              
                <tr>
                  <th scope="row">May 31, 2025</th>
                  <td>
                    Our conference on AI risk has successfully concluded! The event featured insightful discussions, brilliant keynote speakers including <a href="https://yoshuabengio.org/" rel="external nofollow noopener" target="_blank">Yoshua Bengio</a> and <a href="https://www.iasongabriel.com/" rel="external nofollow noopener" target="_blank">Iason Gabriel</a>, and engaging talks on critical AI safety topics. The conference received coverage from Belgian media, including <a href="https://www.standaard.be/media-en-cultuur/als-ai-liegt-en-chanteert-om-haar-doel-te-bereiken-hebben-we-de-technologie-nog-onder-controle/69306377.html" rel="external nofollow noopener" target="_blank">De Standaard</a> and <a href="https://www.tijd.be/ondernemen/technologie/ai-autoriteit-ook-1-procent-kans-op-een-ai-catastrofe-is-onaanvaardbaar/10609127.html" rel="external nofollow noopener" target="_blank">De Tijd</a>.
Hope to see you next year!

                  </td>
                </tr>
                <tr>
                  <th scope="row">May 28, 2025</th>
                  <td>
                    New preprint! We introduce JQL, a systematic approach for multilingual data curation that outperforms existing filtering methods. <a href="https://arxiv.org/abs/2505.22232" rel="external nofollow noopener" target="_blank">Check it out on arXiv</a>.

                  </td>
                </tr>
                <tr>
                  <th scope="row">Mar 30, 2025</th>
                  <td>
                    We’re giving a seminar course about the ethics of Artificial General Intelligence in the summer semester! The course covers AGI basics, alignment and value specification, control and autonomy, systemic risks, and global governance. <a href="https://www.b-it-center.de/caisa/teaching/ai-ethics" rel="external nofollow noopener" target="_blank">Learn more and register here</a>.

                  </td>
                </tr>
                <tr>
                  <th scope="row">Mar 23, 2025</th>
                  <td>
                    Registrations are now open for the <a href="https://www.kuleuven.be/ethics-kuleuven/chair-ai/conference-ai-risks" rel="external nofollow noopener" target="_blank">International Conference on Large-Scale AI Risks</a> from 26-28th May 2025 in Leuven, Belgium. Dr. Florian Mai helped organize this event and we look forward to seeing you there!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Mar 20, 2025</th>
                  <td>
                    Dr. Florian Mai is participating in a <a href="https://www.deutsches-museum.de/bonn/programm/veranstaltung/vertrauenswuerdige-ki" rel="external nofollow noopener" target="_blank">panel discussion on trustworthy AI</a> at the Deutsches Museum Bonn.

                  </td>
                </tr>
                <tr>
                  <th scope="row">Mar 6, 2025</th>
                  <td>
                    Great news! Dr. Florian Mai and collaborators’ paper <a href="https://arxiv.org/abs/2503.13621" rel="external nofollow noopener" target="_blank">“Superalignment with Dynamic Human Values”</a> was accepted at the BiAlign Workshop at ICLR 2025!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Feb 19, 2025</th>
                  <td>
                    The mAI alignment lab started an <a href="/blog/">AI safety reading group</a> at University of Bonn, discussing recent papers on alignment and more! Interested in joining? Subscribe to our <a href="https://listen.uni-bonn.de/wws/info/aisafety" rel="external nofollow noopener" target="_blank">mailing list</a>!

                  </td>
                </tr>
                <tr>
                  <th scope="row">Jan 1, 2025</th>
                  <td>
                    The mAI alignment lab is founded! Dr. Florian Mai started as a Junior Research Group Leader at University of Bonn as part of the <a href="https://caisa-lab.github.io/" rel="external nofollow noopener" target="_blank">CAISA lab</a> headed by Prof. Lucie Flek. The lab’s research will focus on AI safety topics like value alignment, and on reasoning and planning approaches for LLMs.

                  </td>
                </tr>
              </table>
            </div>
          </div>


          <!-- Latest posts -->
          <h2><a href="/blog/" style="color: #0c446b;">safety reading group</a></h2>
          <div class="news">
            <div class="table-responsive" style="max-height: 10vw">
              <table class="table table-sm table-borderless">
              
                <tr>
                  <th scope="row">May 21, 2025</th>
                  <td>
                    <a class="news-title" href="/blog/2025/paperclip-maximizer/">Evaluating the Paperclip Maximizer and Instrumental Goals</a>
                  </td>
                </tr>
                <tr>
                  <th scope="row">May 7, 2025</th>
                  <td>
                    <a class="news-title" href="/blog/2025/gradual-disempowerment/">Gradual Disempowerment and Systemic AI Risks</a>
                  </td>
                </tr>
                <tr>
                  <th scope="row">Apr 9, 2025</th>
                  <td>
                    <a class="news-title" href="/blog/2025/dynamic-normativity/">Dynamic Normativity and Value Alignment</a>
                  </td>
                </tr>
              </table>
            </div>
          </div>


          <!-- Selected papers -->
          <h2><a href="/publications/" style="color: #0c446b;">selected publications</a></h2>
          <div class="publications">
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">BiAlign</abbr></div>

        <!-- Entry bib key -->
        <div id="mai2025superalignment" class="col-sm-8">
        <!-- Title -->
        <div class="title">Superalignment with Dynamic Human Values</div>
        <!-- Author -->
        <div class="author">
        

        <em>Florian Mai</em>, David Kaczér, Nicholas Kluge Corrêa, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Lucie Flek' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In ICLR 2025 Workshop on Bidirectional Human-AI Alignment</em>, 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2503.13621"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Two core challenges of alignment are 1) scalable oversight and 2) accounting for the dynamic nature of human values. While solutions like recursive reward modeling address 1), they do not simultaneously account for 2). We sketch a roadmap for a novel algorithmic framework that trains a superhuman reasoning model to decompose complex tasks into subtasks that are still amenable to human-level guidance. Our approach relies on what we call the part-to-complete generalization hypothesis, which states that the alignment of subtask solutions generalizes to the alignment of complete solutions. We advocate for the need to measure this generalization and propose ways to improve it in the future.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mai2025superalignment</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Superalignment with Dynamic Human Values}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mai, Florian and Kacz{\'e}r, David and Corr{\^e}a, Nicholas Kluge and Flek, Lucie}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICLR 2025 Workshop on Bidirectional Human-AI Alignment}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=WvB9hKKjSc}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2503.13621}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.AI}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">COLM</abbr></div>

        <!-- Entry bib key -->
        <div id="cornille2024learning" class="col-sm-8">
        <!-- Title -->
        <div class="title">Learning to Plan for Language Modeling from Unlabeled Data</div>
        <!-- Author -->
        <div class="author">
        

        Nathan Cornille, Marie-Francine Moens, and <em>Florian Mai</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In First Conference on Language Modeling</em>, 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
          </div>
          
          <div class="badges">
            <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right" data-arxiv-id="2404.00614"></span>
              <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>By training to predict the next token in an unlabeled corpus, large language models learn to perform many tasks without any labeled data. However, their next-token-prediction objective arguably limits their performance in scenarios that require planning, such as writing a coherent article. In this paper, we train a module for planning the future writing process via a self-supervised learning objective. Given the textual context, this planning module learns to predict future abstract writing actions, which correspond to centroids in a clustered text embedding space. By conditioning on these actions, our model extends the successful language model formula to more abstract planning in an unsupervised way. Empirically, we demonstrate that our method improves language modeling performance in general, particularly with respect to the text structure. Because our framework uses a planner module that is unsupervised and external to the language model, new planner modules can be trained at large scale and easily be shared with the community.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">cornille2024learning</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning to Plan for Language Modeling from Unlabeled Data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cornille, Nathan and Moens, Marie-Francine and Mai, Florian}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{First Conference on Language Modeling}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=nT6fQIidrQ}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2404.00614}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>
          </div>


          <!-- Social -->
            <div class="social">
              <div class="contact-icons">
                <a href="mailto:%66%6D%61%69@%75%6E%69-%62%6F%6E%6E.%64%65" title="email"><i class="fas fa-envelope"></i></a>
            

              </div>

              <div class="contact-note">
                You can reach us at fmai@uni-bonn.de

              </div>

            </div>
        </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Florian  Mai. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
